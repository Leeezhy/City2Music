<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8" />
    <title>City Sound to Music</title>
  
    <!-- Âä†ËΩΩ TensorFlow.js ‰∏éÊ®°Âûã -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.9.0"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/yamnet"></script>
  
    <!-- ‚úÖ Êõ¥Êç¢‰∏∫Á®≥ÂÆöÁöÑ Tone.js CDN -->
    <script src="https://cdn.jsdelivr.net/npm/tone@14.8.39/build/Tone.js"></script>
  
    <style>
      body { font-family: sans-serif; padding: 20px; background: #f4f4f4; }
      #status { margin-top: 10px; font-size: 1.2em; color: green; }
      button { font-size: 1em; padding: 10px 20px; }
    </style>
  </head>
  
<body>
  <h1>üéß City Sound to Music</h1>
  <button id="startButton">Start Listening</button>
  <div id="status">Waiting to start...</div>

  <script>
    let model;
    let audioContext;
    let mic;
    let recognizerRunning = false;
    const labelNames = []; // to be populated by model

    const sampler = new Tone.Sampler({
      urls: {
        C4: "https://cdn.jsdelivr.net/gh/Tonejs/Tone.js/examples/audio/casio/C4.mp3",
        D4: "https://cdn.jsdelivr.net/gh/Tonejs/Tone.js/examples/audio/casio/D4.mp3",
        E4: "https://cdn.jsdelivr.net/gh/Tonejs/Tone.js/examples/audio/casio/E4.mp3",
      },
      release: 1,
    }).toDestination();

    async function getTopLabels(scoresTensor, topK = 3) {
      const scores = (await scoresTensor.array())[0];
      const topIndices = scores
        .map((score, idx) => ({ score, idx }))
        .sort((a, b) => b.score - a.score)
        .slice(0, topK);
      return topIndices.map(obj => labelNames[obj.idx]);
    }

    document.getElementById("startButton").onclick = async () => {
      try {
        await Tone.start();
        if (recognizerRunning) return;
        recognizerRunning = true;
        document.getElementById("status").innerText = "Loading model...";
        model = await yamnet.load();
        labelNames.push(...model.labels); // save labels
        document.getElementById("status").innerText = "Model loaded. Waiting for mic...";

        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mic = audioContext.createMediaStreamSource(stream);
        const processor = audioContext.createScriptProcessor(4096, 1, 1);
        mic.connect(processor);
        processor.connect(audioContext.destination);

        const buffer = [];

        processor.onaudioprocess = async (e) => {
          const input = e.inputBuffer.getChannelData(0);
          buffer.push(...input);
          if (buffer.length >= 16000) {
            const slice = buffer.splice(0, 16000);
            const inputTensor = tf.tensor(slice, [1, slice.length]);
            const topLabels = await getTopLabels(await model.predict(inputTensor));
            document.getElementById("status").innerText = "Detected: " + topLabels.join(", ");

            if (topLabels.includes("Car horn")) sampler.triggerAttackRelease("C4", "8n");
            if (topLabels.includes("Speech")) sampler.triggerAttackRelease("D4", "8n");
            if (topLabels.includes("Traffic noise")) sampler.triggerAttackRelease("E4", "8n");
          }
        };
      } catch (err) {
        document.getElementById("status").innerText = "‚ùå Error: " + err.message;
        console.error(err);
      }
    };
  </script>
</body>
</html>
